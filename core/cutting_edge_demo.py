#!/usr/bin/env python3
"""
üöÄ Cutting-Edge LangGraph Collective Intelligence Demo - July 2025

Demonstrates the latest LangGraph patterns:
- Configuration-driven architecture (assistants-demo patterns)
- Ambient agent patterns (LangGraph Academy)
- Streaming execution with real-time updates
- TypedDict state management with Annotated fields
- @tool decorator patterns with automatic schema generation
- ToolNode management and routing
- Advanced interrupt patterns for human-in-loop
- Configuration-driven runtime flexibility

Based on the most advanced patterns available as of July 2025.
"""

import asyncio
import logging
from datetime import datetime
from typing import Dict, Any
from langchain_core.runnables import RunnableConfig

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Import our cutting-edge implementation
from src.aura_intelligence.orchestration.workflows import CollectiveWorkflow


class CuttingEdgeDemo:
    """
    Demonstrates the latest LangGraph patterns and features.
    
    This showcases configuration-driven architecture, streaming execution,
    and ambient agent patterns from the July 2025 LangGraph ecosystem.
    """
    
    def __init__(self):
        self.workflow = CollectiveWorkflow()
        
    async def run_configuration_demo(self):
        """Demonstrate configuration-driven patterns from assistants-demo."""
        
        print("\nüîß Configuration-Driven Architecture Demo")
        print("=" * 60)
        
        # Different configurations for different scenarios
        configs = {
            "development": RunnableConfig(
                configurable={
                    "supervisor_model": "anthropic/claude-3-haiku-latest",
                    "enable_streaming": True,
                    "enable_human_loop": False,
                    "checkpoint_mode": "memory",
                    "memory_provider": "local",
                    "context_window": 3,
                    "risk_thresholds": {
                        "critical": 0.8,
                        "high": 0.6,
                        "medium": 0.3,
                        "low": 0.1
                    }
                }
            ),
            "production": RunnableConfig(
                configurable={
                    "supervisor_model": "anthropic/claude-3-5-sonnet-latest",
                    "observer_model": "anthropic/claude-3-haiku-latest",
                    "analyst_model": "anthropic/claude-3-5-sonnet-latest",
                    "executor_model": "anthropic/claude-3-haiku-latest",
                    "enable_streaming": True,
                    "enable_human_loop": True,
                    "checkpoint_mode": "sqlite",
                    "memory_provider": "langmem",
                    "context_window": 10,
                    "risk_thresholds": {
                        "critical": 0.9,
                        "high": 0.7,
                        "medium": 0.4,
                        "low": 0.1
                    }
                }
            ),
            "high_security": RunnableConfig(
                configurable={
                    "supervisor_model": "anthropic/claude-3-5-sonnet-latest",
                    "enable_streaming": False,
                    "enable_human_loop": True,
                    "checkpoint_mode": "sqlite",
                    "memory_provider": "encrypted",
                    "context_window": 15,
                    "risk_thresholds": {
                        "critical": 0.95,
                        "high": 0.8,
                        "medium": 0.5,
                        "low": 0.2
                    }
                }
            )
        }
        
        # Test each configuration
        for config_name, config in configs.items():
            print(f"\nüéØ Testing {config_name.upper()} configuration:")
            
            # Create test event
            test_event = {
                "type": "security_alert",
                "source": "firewall",
                "severity": "high",
                "message": f"Suspicious activity detected - {config_name} test",
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "ip_address": "192.168.1.100",
                    "attempts": 5,
                    "config_type": config_name
                }
            }
            
            # Process with specific configuration
            result = await self.workflow.process_event(test_event, config)
            
            print(f"  ‚úÖ Status: {result['status']}")
            print(f"  üìä Evidence: {result['evidence_count']} entries")
            print(f"  üéØ Final Step: {result['final_step']}")
            print(f"  üß† Memory Context: {len(result['memory_context'])} items")
            
            if result['insights']:
                insights = result['insights']
                print(f"  üîç Risk Level: {insights.get('risk_level', 'unknown')}")
                print(f"  ‚ö° Actions: {len(insights.get('actions_executed', []))}")
    
    async def run_streaming_demo(self):
        """Demonstrate streaming execution patterns."""
        
        print("\nüåä Streaming Execution Demo")
        print("=" * 60)
        
        # Configuration for streaming
        streaming_config = RunnableConfig(
            configurable={
                "supervisor_model": "anthropic/claude-3-5-sonnet-latest",
                "enable_streaming": True,
                "enable_human_loop": False,
                "checkpoint_mode": "memory"
            }
        )
        
        # Complex event that will trigger multiple steps
        complex_event = {
            "type": "system_failure",
            "source": "database_cluster",
            "severity": "critical",
            "message": "Database cluster experiencing cascading failures",
            "timestamp": datetime.now().isoformat(),
            "metadata": {
                "affected_services": ["user_auth", "payment_processing", "analytics"],
                "error_rate": 0.85,
                "response_time_ms": 5000,
                "connection_pool_exhausted": True
            }
        }
        
        print("üé¨ Processing complex system failure event...")
        print("üì° Streaming real-time updates:")
        
        # Process with streaming enabled
        result = await self.workflow.process_event(complex_event, streaming_config)
        
        print(f"\nüèÅ Final Result:")
        print(f"  Status: {result['status']}")
        print(f"  Workflow ID: {result['workflow_id']}")
        print(f"  Thread ID: {result['thread_id']}")
        print(f"  Evidence Count: {result['evidence_count']}")
        print(f"  Supervisor Decisions: {result['supervisor_decisions']}")
        
        if result['insights']:
            insights = result['insights']
            print(f"  Risk Score: {insights.get('risk_score', 'N/A')}")
            print(f"  Risk Level: {insights.get('risk_level', 'N/A')}")
            print(f"  Actions Executed: {len(insights.get('actions_executed', []))}")
    
    async def run_ambient_patterns_demo(self):
        """Demonstrate ambient agent patterns from LangGraph Academy."""
        
        print("\nüåü Ambient Agent Patterns Demo")
        print("=" * 60)
        
        # Configuration for ambient patterns
        ambient_config = RunnableConfig(
            configurable={
                "supervisor_model": "anthropic/claude-3-5-sonnet-latest",
                "enable_streaming": True,
                "enable_human_loop": False,
                "checkpoint_mode": "sqlite",
                "memory_provider": "local",
                "context_window": 8,
                "supervisor_prompt": """
                You are an ambient collective intelligence supervisor operating in the background.
                Your role is to continuously monitor, analyze, and respond to system events
                with minimal human intervention. Make intelligent routing decisions based on
                the current context and evidence patterns.
                
                Available tools: observe_system_event, analyze_risk_patterns, execute_remediation
                Decision: Choose the next tool to call or FINISH if workflow is complete.
                """
            }
        )
        
        # Series of related events to show ambient processing
        ambient_events = [
            {
                "type": "performance_degradation",
                "source": "api_gateway",
                "severity": "medium",
                "message": "API response times increasing",
                "timestamp": datetime.now().isoformat(),
                "metadata": {"avg_response_ms": 800, "p95_response_ms": 1200}
            },
            {
                "type": "error_spike",
                "source": "user_service",
                "severity": "high",
                "message": "Error rate spike detected",
                "timestamp": datetime.now().isoformat(),
                "metadata": {"error_rate": 0.15, "affected_endpoints": ["/login", "/profile"]}
            },
            {
                "type": "resource_exhaustion",
                "source": "kubernetes_cluster",
                "severity": "critical",
                "message": "Memory usage approaching limits",
                "timestamp": datetime.now().isoformat(),
                "metadata": {"memory_usage_percent": 92, "cpu_usage_percent": 78}
            }
        ]
        
        print("ü§ñ Processing events through ambient intelligence...")
        
        for i, event in enumerate(ambient_events, 1):
            print(f"\nüì° Event {i}: {event['type']} ({event['severity']})")
            
            result = await self.workflow.process_event(event, ambient_config)
            
            print(f"  ‚úÖ Processed: {result['status']}")
            print(f"  üîç Evidence: {result['evidence_count']} entries")
            print(f"  üéØ Final Step: {result['final_step']}")
            
            if result['insights'] and result['insights'].get('risk_level'):
                risk_level = result['insights']['risk_level']
                actions = len(result['insights'].get('actions_executed', []))
                print(f"  ‚ö†Ô∏è  Risk: {risk_level} | Actions: {actions}")
    
    async def run_system_health_demo(self):
        """Demonstrate system health monitoring."""
        
        print("\nüíö System Health Demo")
        print("=" * 60)
        
        health = self.workflow.get_system_health()
        
        print("üè• System Health Status:")
        print(f"  Workflow ID: {health['workflow_id']}")
        print(f"  App Initialized: {health['app_initialized']}")
        print(f"  Configuration Driven: {health['config_driven']}")
        print(f"  LangGraph Version: {health['langgraph_version']}")
        print(f"  Patterns: {', '.join(health['patterns'])}")
        print(f"  Timestamp: {health['timestamp']}")
    
    async def run_complete_demo(self):
        """Run the complete cutting-edge demonstration."""
        
        print("üöÄ CUTTING-EDGE LANGGRAPH COLLECTIVE INTELLIGENCE DEMO")
        print("üéØ July 2025 - Latest Patterns & Features")
        print("=" * 80)
        
        try:
            # Run all demonstrations
            await self.run_configuration_demo()
            await self.run_streaming_demo()
            await self.run_ambient_patterns_demo()
            await self.run_system_health_demo()
            
            print("\nüéâ DEMO COMPLETE!")
            print("‚ú® Successfully demonstrated cutting-edge LangGraph patterns:")
            print("   ‚Ä¢ Configuration-driven architecture")
            print("   ‚Ä¢ Streaming execution with real-time updates")
            print("   ‚Ä¢ Ambient agent patterns")
            print("   ‚Ä¢ TypedDict state management")
            print("   ‚Ä¢ @tool decorator patterns")
            print("   ‚Ä¢ Advanced routing and decision making")
            print("   ‚Ä¢ Professional error handling")
            
        except Exception as e:
            logger.error(f"‚ùå Demo failed: {e}")
            print(f"\n‚ùå Demo failed: {e}")


async def main():
    """Main entry point for the cutting-edge demo."""
    
    demo = CuttingEdgeDemo()
    await demo.run_complete_demo()


if __name__ == "__main__":
    asyncio.run(main())
