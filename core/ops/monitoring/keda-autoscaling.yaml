# ðŸš€ KEDA 2.14 Cost-Aware Autoscaling Configuration
# 
# Modern Kubernetes Event-Driven Autoscaling with:
# - Multi-signal scaling triggers (latency, CPU, queue depth)
# - Cost optimization with spot instance preferences
# - Business-impact aware scaling decisions
# - Agent workload specific scaling patterns

apiVersion: v1
kind: Namespace
metadata:
  name: aura-intelligence
  labels:
    name: aura-intelligence
    monitoring: enabled

---
# Search API Autoscaling - Latency and Load Based
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: search-api-scaler
  namespace: aura-intelligence
  labels:
    app: aura-intelligence
    component: search-api
spec:
  scaleTargetRef:
    name: search-api
  
  # Scaling configuration
  minReplicaCount: 2    # Always maintain 2 replicas for availability
  maxReplicaCount: 20   # Scale up to 20 for high load
  cooldownPeriod: 60    # Wait 60s between scale-down operations
  pollingInterval: 15   # Check metrics every 15s
  
  # Advanced scaling behavior
  advanced:
    restoreToOriginalReplicaCount: true
    horizontalPodAutoscalerConfig:
      name: search-api-hpa
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300  # 5 min stabilization
          policies:
          - type: Percent
            value: 50    # Scale down max 50% at a time
            periodSeconds: 60
          - type: Pods
            value: 2     # Or max 2 pods at a time
            periodSeconds: 60
          selectPolicy: Min  # Use the more conservative policy
        scaleUp:
          stabilizationWindowSeconds: 60   # 1 min stabilization
          policies:
          - type: Percent
            value: 100   # Scale up max 100% at a time
            periodSeconds: 30
          - type: Pods
            value: 5     # Or max 5 pods at a time
            periodSeconds: 30
          selectPolicy: Max  # Use the more aggressive policy
  
  triggers:
  # Primary trigger: Search latency SLA
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: search_latency_p95
      query: |
        histogram_quantile(0.95,
          sum(rate(aura_search_duration_bucket{tier!="api"}[2m])) by (le)
        )
      threshold: '100'  # Scale up if P95 > 100ms
    authenticationRef:
      name: prometheus-auth
  
  # Secondary trigger: Request rate per pod
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: requests_per_pod
      query: |
        sum(rate(aura_search_requests_total[2m])) 
        / 
        sum(kube_deployment_status_replicas{deployment="search-api"})
      threshold: '50'   # Scale up if > 50 requests/sec per pod
    authenticationRef:
      name: prometheus-auth
  
  # Tertiary trigger: CPU utilization
  - type: cpu
    metadata:
      type: Utilization
      value: '70'       # Scale up if CPU > 70%
  
  # Quaternary trigger: Memory utilization
  - type: memory
    metadata:
      type: Utilization
      value: '80'       # Scale up if memory > 80%

---
# Archival Jobs Autoscaling - Queue Depth Based
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: archival-jobs-scaler
  namespace: aura-intelligence
  labels:
    app: aura-intelligence
    component: archival-jobs
spec:
  scaleTargetRef:
    name: archival-jobs
  
  minReplicaCount: 1
  maxReplicaCount: 10
  cooldownPeriod: 300   # 5 min cooldown for batch jobs
  pollingInterval: 30   # Check every 30s
  
  triggers:
  # Scale based on pending archival work
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: pending_archival_records
      query: |
        sum(
          aura_memory_usage{tier="hot"} 
          / 
          (1024 * 1024 * 1024)  # Convert to GB
        ) - 1  # Scale when hot memory > 1GB
      threshold: '0.5'  # Scale up when > 0.5GB over threshold
    authenticationRef:
      name: prometheus-auth
  
  # Scale based on archival job failure rate
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: archival_failure_rate
      query: |
        rate(aura_archival_jobs{status="error"}[5m]) 
        / 
        rate(aura_archival_jobs[5m])
      threshold: '0.1'  # Scale up if failure rate > 10%
    authenticationRef:
      name: prometheus-auth

---
# Agent Orchestrator Autoscaling - Decision Load Based
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: agent-orchestrator-scaler
  namespace: aura-intelligence
  labels:
    app: aura-intelligence
    component: agent-orchestrator
spec:
  scaleTargetRef:
    name: agent-orchestrator
  
  minReplicaCount: 1
  maxReplicaCount: 8
  cooldownPeriod: 120   # 2 min cooldown
  pollingInterval: 20   # Check every 20s
  
  triggers:
  # Scale based on agent decision queue depth
  - type: redis
    metadata:
      address: redis:6379
      listName: agent_decision_queue
      listLength: '10'  # Scale up if > 10 pending decisions
    authenticationRef:
      name: redis-auth
  
  # Scale based on agent decision latency
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: agent_decision_latency_p95
      query: |
        histogram_quantile(0.95,
          sum(rate(aura_agent_decision_time_bucket[2m])) by (le)
        )
      threshold: '1000'  # Scale up if P95 > 1000ms
    authenticationRef:
      name: prometheus-auth

---
# Cost-Aware External Scaler for Budget Control
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: cost-aware-scaler
  namespace: aura-intelligence
  labels:
    app: aura-intelligence
    component: cost-optimizer
spec:
  scaleTargetRef:
    name: search-api
  
  minReplicaCount: 2
  maxReplicaCount: 50   # Higher limit but controlled by cost
  cooldownPeriod: 180   # 3 min cooldown for cost decisions
  
  triggers:
  # External scaler for cost optimization
  - type: external
    metadata:
      scalerAddress: cost-optimizer:9090
      # Cost optimization parameters
      maxHourlyCost: "100"           # Max $100/hour
      spotInstanceRatio: "0.7"       # Prefer 70% spot instances
      costPerReplica: "0.05"         # Estimated cost per replica per hour
      businessHours: "09:00-17:00"   # Higher budget during business hours
      timezone: "UTC"
      # Performance thresholds that override cost limits
      criticalLatencyThreshold: "500"  # Override cost if latency > 500ms
      errorRateThreshold: "0.05"       # Override cost if error rate > 5%

---
# Authentication for Prometheus
apiVersion: v1
kind: Secret
metadata:
  name: prometheus-auth
  namespace: aura-intelligence
type: Opaque
data:
  # Base64 encoded credentials (would be properly managed in production)
  username: cHJvbWV0aGV1cw==  # prometheus
  password: cGFzc3dvcmQ=      # password

---
# Authentication for Redis
apiVersion: v1
kind: Secret
metadata:
  name: redis-auth
  namespace: aura-intelligence
type: Opaque
data:
  # Base64 encoded Redis password
  password: cmVkaXNwYXNzd29yZA==  # redispassword

---
# KEDA Operator Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: keda-config
  namespace: keda
data:
  # Global KEDA configuration
  config.yaml: |
    operator:
      # Enable metrics server for HPA integration
      metricsBindAddress: ":8080"
      healthProbeBindAddress: ":8081"
      
      # Resource limits for KEDA operator
      resources:
        limits:
          cpu: 1000m
          memory: 1000Mi
        requests:
          cpu: 100m
          memory: 20Mi
    
    # Webhook configuration
    webhook:
      port: 9443
      certDir: /tmp/k8s-webhook-server/serving-certs
    
    # Metrics server configuration
    metricsServer:
      # Enable Prometheus metrics
      bindAddress: ":8080"
      # Audit configuration
      auditConfig:
        logFormat: "json"
        logOutputVolumeClaim: "keda-audit-logs"

---
# ServiceMonitor for KEDA metrics
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: keda-metrics
  namespace: keda
  labels:
    app: keda-operator
spec:
  selector:
    matchLabels:
      app: keda-operator
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    scheme: http

---
# PrometheusRule for KEDA alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: keda-alerts
  namespace: aura-intelligence
spec:
  groups:
  - name: keda.scaling
    interval: 30s
    rules:
    - alert: KEDAScalerError
      expr: increase(keda_scaler_errors_total[5m]) > 0
      for: 2m
      labels:
        severity: warning
        component: keda
      annotations:
        summary: "KEDA scaler error detected"
        description: "KEDA scaler {{ $labels.scaler }} has encountered {{ $value }} errors in the last 5 minutes"
        runbook_url: "https://docs.aura-intelligence.com/runbooks/keda-errors"
    
    - alert: ExcessiveScaling
      expr: |
        increase(keda_scaled_object_paused_total[10m]) > 5
        or
        rate(kube_deployment_status_replicas[5m]) > 2
      for: 5m
      labels:
        severity: warning
        component: autoscaling
      annotations:
        summary: "Excessive scaling activity detected"
        description: "Deployment {{ $labels.deployment }} is scaling too frequently, indicating potential instability"
        runbook_url: "https://docs.aura-intelligence.com/runbooks/scaling-instability"
    
    - alert: CostBudgetExceeded
      expr: |
        sum(
          keda_scaled_object_current_replicas * on(deployment) group_left()
          label_replace(
            prometheus_config_last_reload_successful, 
            "deployment", "$1", "job", "(.+)"
          )
        ) * 0.05 > 100  # $100/hour budget
      for: 10m
      labels:
        severity: critical
        component: cost-optimization
      annotations:
        summary: "Hourly cost budget exceeded"
        description: "Current scaling configuration exceeds $100/hour budget"
        runbook_url: "https://docs.aura-intelligence.com/runbooks/cost-budget-exceeded"
