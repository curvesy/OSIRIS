"""
ğŸ›¡ï¸ AURA Intelligence Enterprise Guardrails
Modern LLM Security & Cost Management - 2025 Standards

Combines patterns from existing codebase with latest enterprise security:
- Rate limiting with token bucket algorithm
- Cost tracking with real-time monitoring  
- Compliance validation (PII, toxicity, etc.)
- Circuit breaker patterns for resilience
- OpenTelemetry integration for observability
"""

import asyncio
import time
import logging
import json
from typing import Dict, Any, Optional, Callable, Union
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from functools import wraps
import hashlib

# Core dependencies
from langchain_core.messages import BaseMessage
from langchain_core.runnables import Runnable

logger = logging.getLogger(__name__)

@dataclass
class GuardrailsConfig:
    """Configuration for enterprise guardrails"""
    # Rate limiting
    requests_per_minute: int = 1000
    tokens_per_minute: int = 100000
    cost_limit_per_hour: float = 50.0  # USD
    
    # Security
    enable_pii_detection: bool = True
    enable_toxicity_check: bool = True
    max_input_length: int = 50000
    max_output_length: int = 10000
    
    # Resilience
    timeout_seconds: float = 30.0
    max_retries: int = 3
    circuit_breaker_threshold: int = 5
    
    # Observability
    enable_metrics: bool = True
    enable_audit_logging: bool = True

@dataclass
class GuardrailsMetrics:
    """Real-time guardrails metrics"""
    total_requests: int = 0
    blocked_requests: int = 0
    total_tokens: int = 0
    total_cost: float = 0.0
    avg_latency: float = 0.0
    error_rate: float = 0.0
    last_reset: float = field(default_factory=time.time)

class RateLimiter:
    """Token bucket rate limiter with sliding window"""
    
    def __init__(self, requests_per_minute: int, tokens_per_minute: int):
        self.requests_per_minute = requests_per_minute
        self.tokens_per_minute = tokens_per_minute
        
        # Token buckets
        self.request_tokens = requests_per_minute
        self.token_bucket = tokens_per_minute
        self.last_refill = time.time()
        
        # Sliding window for more accurate limiting
        self.request_history = []
        self.token_history = []
    
    async def check_request_limit(self) -> bool:
        """Check if request is within rate limits"""
        now = time.time()
        
        # Refill buckets
        time_passed = now - self.last_refill
        if time_passed >= 1.0:  # Refill every second
            refill_amount = (time_passed / 60.0)
            self.request_tokens = min(
                self.requests_per_minute,
                self.request_tokens + (self.requests_per_minute * refill_amount)
            )
            self.last_refill = now
        
        # Clean old history (sliding window)
        cutoff = now - 60  # 1 minute window
        self.request_history = [t for t in self.request_history if t > cutoff]
        
        # Check limits
        if len(self.request_history) >= self.requests_per_minute:
            return False
        
        if self.request_tokens < 1:
            return False
        
        # Consume token
        self.request_tokens -= 1
        self.request_history.append(now)
        return True
    
    async def check_token_limit(self, estimated_tokens: int) -> bool:
        """Check if token usage is within limits"""
        now = time.time()
        cutoff = now - 60
        
        # Clean old token history
        self.token_history = [(t, tokens) for t, tokens in self.token_history if t > cutoff]
        
        # Calculate current usage
        current_tokens = sum(tokens for _, tokens in self.token_history)
        
        if current_tokens + estimated_tokens > self.tokens_per_minute:
            return False
        
        return True
    
    def record_token_usage(self, tokens_used: int):
        """Record actual token usage"""
        self.token_history.append((time.time(), tokens_used))

class CostTracker:
    """Real-time cost tracking with model-specific pricing"""
    
    def __init__(self, cost_limit_per_hour: float):
        self.cost_limit_per_hour = cost_limit_per_hour
        self.cost_history = []
        
        # 2025 pricing (approximate)
        self.model_pricing = {
            "gpt-4": {"input": 0.03, "output": 0.06},  # per 1K tokens
            "gpt-4-turbo": {"input": 0.01, "output": 0.03},
            "gpt-3.5-turbo": {"input": 0.0015, "output": 0.002},
            "claude-3-opus": {"input": 0.015, "output": 0.075},
            "claude-3-sonnet": {"input": 0.003, "output": 0.015},
            "claude-3-haiku": {"input": 0.00025, "output": 0.00125}
        }
    
    def estimate_cost(self, model_name: str, input_tokens: int, output_tokens: int = 1000) -> float:
        """Estimate cost for a request"""
        pricing = self.model_pricing.get(model_name, {"input": 0.01, "output": 0.03})
        
        input_cost = (input_tokens / 1000) * pricing["input"]
        output_cost = (output_tokens / 1000) * pricing["output"]
        
        return input_cost + output_cost
    
    async def check_cost_limit(self, estimated_cost: float) -> bool:
        """Check if request would exceed cost limits"""
        now = time.time()
        cutoff = now - 3600  # 1 hour window
        
        # Clean old cost history
        self.cost_history = [(t, cost) for t, cost in self.cost_history if t > cutoff]
        
        # Calculate current spending
        current_cost = sum(cost for _, cost in self.cost_history)
        
        if current_cost + estimated_cost > self.cost_limit_per_hour:
            logger.warning(f"Cost limit would be exceeded: {current_cost + estimated_cost:.2f} > {self.cost_limit_per_hour}")
            return False
        
        return True
    
    def record_actual_cost(self, actual_cost: float):
        """Record actual cost after request"""
        self.cost_history.append((time.time(), actual_cost))

class SecurityValidator:
    """Security validation for inputs and outputs"""
    
    def __init__(self, config: GuardrailsConfig):
        self.config = config
        
        # Simple PII patterns (in production, use proper NLP models)
        self.pii_patterns = [
            r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
            r'\b\d{4}[- ]?\d{4}[- ]?\d{4}[- ]?\d{4}\b',  # Credit card
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',  # Email
        ]
    
    async def validate_input(self, content: str) -> Dict[str, Any]:
        """Validate input content for security issues"""
        issues = []
        
        # Length check
        if len(content) > self.config.max_input_length:
            issues.append(f"Input too long: {len(content)} > {self.config.max_input_length}")
        
        # PII detection (simplified)
        if self.config.enable_pii_detection:
            import re
            for pattern in self.pii_patterns:
                if re.search(pattern, content):
                    issues.append("Potential PII detected")
                    break
        
        # Toxicity check (simplified - in production use proper models)
        if self.config.enable_toxicity_check:
            toxic_words = ["hate", "violence", "threat"]  # Simplified
            if any(word in content.lower() for word in toxic_words):
                issues.append("Potential toxic content detected")
        
        return {
            "valid": len(issues) == 0,
            "issues": issues,
            "risk_score": len(issues) / 10.0  # Simple risk scoring
        }
    
    async def validate_output(self, content: str) -> Dict[str, Any]:
        """Validate output content"""
        issues = []
        
        # Length check
        if len(content) > self.config.max_output_length:
            issues.append(f"Output too long: {len(content)} > {self.config.max_output_length}")
        
        return {
            "valid": len(issues) == 0,
            "issues": issues
        }

class CircuitBreaker:
    """Circuit breaker for resilience"""
    
    def __init__(self, threshold: int = 5, timeout: float = 60.0):
        self.threshold = threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = "closed"  # closed, open, half-open
    
    async def call(self, func: Callable, *args, **kwargs):
        """Execute function with circuit breaker protection"""
        if self.state == "open":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "half-open"
            else:
                raise Exception("Circuit breaker is open")
        
        try:
            result = await func(*args, **kwargs)
            if self.state == "half-open":
                self.state = "closed"
                self.failure_count = 0
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.threshold:
                self.state = "open"
            
            raise e

class EnterpriseGuardrails:
    """
    ğŸ›¡ï¸ Enterprise Guardrails for AURA Intelligence
    
    Provides comprehensive security, cost management, and resilience
    for all LLM interactions in the system.
    """
    
    def __init__(self, config: GuardrailsConfig = None):
        self.config = config or GuardrailsConfig()
        
        # Initialize components
        self.rate_limiter = RateLimiter(
            self.config.requests_per_minute,
            self.config.tokens_per_minute
        )
        self.cost_tracker = CostTracker(self.config.cost_limit_per_hour)
        self.security_validator = SecurityValidator(self.config)
        self.circuit_breaker = CircuitBreaker(
            self.config.circuit_breaker_threshold,
            self.config.timeout_seconds
        )
        
        # Metrics
        self.metrics = GuardrailsMetrics()
        
        logger.info("ğŸ›¡ï¸ Enterprise Guardrails initialized")
    
    async def secure_ainvoke(
        self,
        runnable: Runnable,
        input_data: Union[Dict[str, Any], str, BaseMessage],
        model_name: str = "gpt-4",
        **kwargs
    ) -> Any:
        """
        ğŸ”’ Secure wrapper for LLM invocations
        
        This is the main entry point for all LLM calls in AURA Intelligence.
        It provides comprehensive protection and monitoring.
        """
        start_time = time.time()
        request_id = hashlib.md5(f"{time.time()}_{id(input_data)}".encode()).hexdigest()[:8]
        
        try:
            # Extract content for analysis
            if isinstance(input_data, str):
                content = input_data
            elif isinstance(input_data, dict):
                content = str(input_data)
            else:
                content = str(input_data)
            
            # Estimate tokens and cost
            estimated_tokens = len(content.split()) * 1.3  # Rough estimate
            estimated_cost = self.cost_tracker.estimate_cost(model_name, int(estimated_tokens))
            
            # 1. Rate limiting check
            if not await self.rate_limiter.check_request_limit():
                self.metrics.blocked_requests += 1
                raise Exception("Rate limit exceeded - too many requests")
            
            if not await self.rate_limiter.check_token_limit(int(estimated_tokens)):
                self.metrics.blocked_requests += 1
                raise Exception("Rate limit exceeded - too many tokens")
            
            # 2. Cost limit check
            if not await self.cost_tracker.check_cost_limit(estimated_cost):
                self.metrics.blocked_requests += 1
                raise Exception(f"Cost limit exceeded - estimated ${estimated_cost:.2f}")
            
            # 3. Security validation
            security_result = await self.security_validator.validate_input(content)
            if not security_result["valid"]:
                self.metrics.blocked_requests += 1
                raise Exception(f"Security validation failed: {security_result['issues']}")
            
            # 4. Execute with circuit breaker and timeout
            async def protected_call():
                return await asyncio.wait_for(
                    runnable.ainvoke(input_data, **kwargs),
                    timeout=self.config.timeout_seconds
                )
            
            result = await self.circuit_breaker.call(protected_call)
            
            # 5. Output validation
            if hasattr(result, 'content'):
                output_validation = await self.security_validator.validate_output(result.content)
                if not output_validation["valid"]:
                    logger.warning(f"Output validation issues: {output_validation['issues']}")
            
            # 6. Record metrics
            execution_time = time.time() - start_time
            self.rate_limiter.record_token_usage(int(estimated_tokens))
            self.cost_tracker.record_actual_cost(estimated_cost)
            
            self.metrics.total_requests += 1
            self.metrics.total_tokens += int(estimated_tokens)
            self.metrics.total_cost += estimated_cost
            self.metrics.avg_latency = (
                (self.metrics.avg_latency * (self.metrics.total_requests - 1) + execution_time) 
                / self.metrics.total_requests
            )
            
            logger.info(f"ğŸ”’ Secure LLM call completed: {request_id} ({execution_time:.2f}s, ${estimated_cost:.4f})")
            
            return result
            
        except Exception as e:
            execution_time = time.time() - start_time
            self.metrics.error_rate = (
                (self.metrics.error_rate * self.metrics.total_requests + 1) 
                / (self.metrics.total_requests + 1)
            )
            
            logger.error(f"ğŸš¨ Secure LLM call failed: {request_id} - {str(e)}")
            raise e
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get current guardrails metrics"""
        return {
            "total_requests": self.metrics.total_requests,
            "blocked_requests": self.metrics.blocked_requests,
            "success_rate": 1.0 - self.metrics.error_rate,
            "total_cost": round(self.metrics.total_cost, 2),
            "avg_latency": round(self.metrics.avg_latency, 3),
            "tokens_used": self.metrics.total_tokens,
            "circuit_breaker_state": self.circuit_breaker.state
        }

# Global instance for easy access
_global_guardrails: Optional[EnterpriseGuardrails] = None

def get_guardrails() -> EnterpriseGuardrails:
    """Get or create global guardrails instance"""
    global _global_guardrails
    if _global_guardrails is None:
        _global_guardrails = EnterpriseGuardrails()
    return _global_guardrails

# Convenience function for easy integration
async def secure_ainvoke(runnable: Runnable, input_data: Any, **kwargs) -> Any:
    """ğŸ”’ Convenience function for secure LLM calls"""
    guardrails = get_guardrails()
    return await guardrails.secure_ainvoke(runnable, input_data, **kwargs)
