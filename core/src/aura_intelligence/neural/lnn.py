"""
Liquid Neural Networks (LNN) implementation for AURA Intelligence.

Based on the latest research from MIT (2025) and Liquid AI, this module implements
continuous-time neural networks inspired by C. elegans nervous system. These networks
offer superior efficiency, adaptability, and interpretability compared to traditional
architectures.

Key Features:
- Continuous-time dynamics with ODE solvers
- Edge-optimized variants for deployment on resource-constrained devices
- Dynamic parameter adjustment without retraining
- Integration with Byzantine consensus for distributed decision-making
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Any, Optional, Tuple, List, Union, Callable
from dataclasses import dataclass, field
from datetime import datetime, timezone
import numpy as np
from enum import Enum
import structlog
from opentelemetry import trace, metrics

from ..observability import create_tracer, create_meter

logger = structlog.get_logger()
tracer = create_tracer("lnn")
meter = create_meter("lnn")

# Metrics
lnn_inference_time = meter.create_histogram(
    name="aura.lnn.inference_time",
    description="LNN inference time in milliseconds",
    unit="ms"
)

lnn_memory_usage = meter.create_gauge(
    name="aura.lnn.memory_usage",
    description="LNN memory usage in MB",
    unit="MB"
)

lnn_adaptations = meter.create_counter(
    name="aura.lnn.adaptations",
    description="Number of dynamic adaptations performed"
)


class ODESolver(Enum):
    """ODE solver types for continuous-time dynamics."""
    EULER = "euler"
    RK4 = "rk4"
    ADAPTIVE = "adaptive"
    SEMI_IMPLICIT = "semi_implicit"  # For edge deployment


@dataclass
class LNNConfig:
    """Configuration for Liquid Neural Networks."""
    # Architecture
    input_size: int
    hidden_size: int
    output_size: int
    num_layers: int = 3
    
    # Continuous-time dynamics
    time_constant: float = 1.0
    ode_solver: ODESolver = ODESolver.SEMI_IMPLICIT
    solver_steps: int = 10
    
    # Liquid properties
    adaptivity_rate: float = 0.1
    sparsity: float = 0.8  # For edge efficiency
    
    # Edge optimization
    quantization_bits: Optional[int] = None  # For edge deployment
    pruning_threshold: float = 0.01
    
    # Byzantine consensus integration
    consensus_enabled: bool = False
    consensus_threshold: float = 0.67  # 2/3 majority
    
    # Performance
    use_cuda: bool = torch.cuda.is_available()
    mixed_precision: bool = True
    
    # Monitoring
    track_dynamics: bool = True
    save_trajectories: bool = False


@dataclass
class LNNMetrics:
    """Metrics for monitoring LNN performance."""
    inference_time_ms: float = 0.0
    memory_usage_mb: float = 0.0
    adaptation_count: int = 0
    sparsity_ratio: float = 0.0
    energy_efficiency: float = 0.0  # FLOPS/Watt
    consensus_rounds: int = 0
    edge_latency_ms: float = 0.0


class LiquidCell(nn.Module):
    """
    Basic Liquid Cell implementing continuous-time dynamics.
    
    Based on the equation:
    dx/dt = -x/τ + f(x, I, t, θ)(A - x)
    
    Where:
    - x: hidden state
    - τ: time constant
    - f: nonlinear function
    - I: input
    - A: bias/equilibrium
    - θ: parameters
    """
    
    def __init__(self, input_size: int, hidden_size: int, config: LNNConfig):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.config = config
        
        # Learnable parameters
        self.W_in = nn.Parameter(torch.randn(input_size, hidden_size) * 0.1)
        self.W_rec = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.1)
        self.bias = nn.Parameter(torch.zeros(hidden_size))
        
        # Time constants (learnable)
        self.tau = nn.Parameter(torch.ones(hidden_size) * config.time_constant)
        
        # Liquid-specific parameters
        self.A = nn.Parameter(torch.ones(hidden_size))  # Equilibrium points
        self.sigma = nn.Parameter(torch.ones(hidden_size) * 0.5)  # Sensitivity
        
        # Sparsity mask for edge efficiency
        if config.sparsity > 0:
            self.register_buffer(
                'sparsity_mask',
                self._create_sparsity_mask()
            )
        
    def _create_sparsity_mask(self) -> torch.Tensor:
        """Create sparse connectivity mask for edge deployment."""
        mask = torch.rand(self.hidden_size, self.hidden_size) > self.config.sparsity
        return mask.float()
    
    def forward(
        self,
        input: torch.Tensor,
        hidden: torch.Tensor,
        dt: float = 0.1
    ) -> torch.Tensor:
        """
        Forward pass with continuous-time dynamics.
        
        Args:
            input: Input tensor [batch_size, input_size]
            hidden: Hidden state [batch_size, hidden_size]
            dt: Time step for ODE solver
            
        Returns:
            Updated hidden state
        """
        # Input transformation
        i_input = torch.matmul(input, self.W_in)
        
        # Recurrent transformation with sparsity
        if hasattr(self, 'sparsity_mask'):
            W_rec_sparse = self.W_rec * self.sparsity_mask
            i_rec = torch.matmul(hidden, W_rec_sparse.t())
        else:
            i_rec = torch.matmul(hidden, self.W_rec.t())
        
        # Nonlinear dynamics
        f = torch.sigmoid(i_input + i_rec + self.bias)
        
        # ODE: dx/dt = -x/τ + f(A - x)
        if self.config.ode_solver == ODESolver.EULER:
            # Simple Euler method
            dx_dt = -hidden / self.tau + f * (self.A - hidden)
            hidden_new = hidden + dt * dx_dt
            
        elif self.config.ode_solver == ODESolver.SEMI_IMPLICIT:
            # Semi-implicit Euler (more stable for edge)
            denominator = 1 + dt / self.tau + dt * f
            numerator = hidden + dt * f * self.A
            hidden_new = numerator / denominator
            
        else:
            # RK4 or adaptive methods
            hidden_new = self._rk4_step(hidden, input, dt)
        
        return hidden_new
    
    def _rk4_step(
        self,
        hidden: torch.Tensor,
        input: torch.Tensor,
        dt: float
    ) -> torch.Tensor:
        """Runge-Kutta 4th order integration."""
        def dynamics(h):
            i_in = torch.matmul(input, self.W_in)
            i_rec = torch.matmul(h, self.W_rec.t())
            f = torch.sigmoid(i_in + i_rec + self.bias)
            return -h / self.tau + f * (self.A - h)
        
        k1 = dynamics(hidden)
        k2 = dynamics(hidden + 0.5 * dt * k1)
        k3 = dynamics(hidden + 0.5 * dt * k2)
        k4 = dynamics(hidden + dt * k3)
        
        return hidden + (dt / 6.0) * (k1 + 2*k2 + 2*k3 + k4)
    
    def adapt_parameters(self, error_signal: torch.Tensor):
        """
        Dynamic parameter adaptation based on error signal.
        This is what makes LNNs "liquid" - they can adapt without retraining.
        """
        with torch.no_grad():
            # Adapt time constants based on error
            self.tau.data += self.config.adaptivity_rate * error_signal.mean(0)
            self.tau.data = torch.clamp(self.tau.data, 0.1, 10.0)
            
            # Adapt sensitivity
            self.sigma.data *= (1 + self.config.adaptivity_rate * error_signal.std())
            
            lnn_adaptations.add(1)


class LiquidLayer(nn.Module):
    """
    A layer of Liquid Cells with advanced features.
    """
    
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        config: LNNConfig,
        is_output: bool = False
    ):
        super().__init__()
        self.config = config
        self.is_output = is_output
        
        # Main liquid cell
        self.cell = LiquidCell(input_size, hidden_size, config)
        
        # Layer normalization for stability
        self.layer_norm = nn.LayerNorm(hidden_size)
        
        # Dropout for regularization
        self.dropout = nn.Dropout(0.1)
        
        # Output projection if needed
        if is_output:
            self.output_proj = nn.Linear(hidden_size, config.output_size)
    
    def forward(
        self,
        input: torch.Tensor,
        hidden: Optional[torch.Tensor] = None,
        time_steps: int = None
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Forward pass through the layer.
        
        Returns:
            (output, final_hidden_state)
        """
        batch_size = input.size(0)
        time_steps = time_steps or self.config.solver_steps
        
        if hidden is None:
            hidden = torch.zeros(
                batch_size,
                self.cell.hidden_size,
                device=input.device
            )
        
        # Continuous-time evolution
        dt = 1.0 / time_steps
        trajectory = []
        
        for t in range(time_steps):
            hidden = self.cell(input, hidden, dt)
            hidden = self.layer_norm(hidden)
            
            if self.config.save_trajectories:
                trajectory.append(hidden.clone())
        
        # Output
        output = hidden
        if not self.is_output:
            output = self.dropout(output)
        else:
            output = self.output_proj(output)
        
        return output, hidden


class LiquidNeuralNetwork(nn.Module):
    """
    Complete Liquid Neural Network with multiple layers.
    
    This implementation includes:
    - Multi-layer architecture
    - Continuous-time dynamics
    - Edge optimization features
    - Byzantine consensus integration
    - Adaptive learning without retraining
    """
    
    def __init__(self, config: LNNConfig):
        super().__init__()
        self.config = config
        self.metrics = LNNMetrics()
        
        # Build layers
        self.layers = nn.ModuleList()
        
        # Input layer
        self.layers.append(
            LiquidLayer(
                config.input_size,
                config.hidden_size,
                config,
                is_output=False
            )
        )
        
        # Hidden layers
        for _ in range(config.num_layers - 2):
            self.layers.append(
                LiquidLayer(
                    config.hidden_size,
                    config.hidden_size,
                    config,
                    is_output=False
                )
            )
        
        # Output layer
        self.layers.append(
            LiquidLayer(
                config.hidden_size,
                config.hidden_size,
                config,
                is_output=True
            )
        )
        
        # Attention mechanism for temporal features
        self.temporal_attention = nn.MultiheadAttention(
            config.hidden_size,
            num_heads=4,
            dropout=0.1
        )
        
        # Initialize metrics tracking
        self._init_metrics()
    
    def _init_metrics(self):
        """Initialize metrics tracking."""
        self.register_buffer('inference_times', torch.zeros(100))
        self.register_buffer('memory_snapshots', torch.zeros(100))
        self.inference_count = 0
    
    @tracer.start_as_current_span("lnn_forward")
    def forward(
        self,
        x: torch.Tensor,
        hidden_states: Optional[List[torch.Tensor]] = None,
        return_trajectories: bool = False
    ) -> Union[torch.Tensor, Tuple[torch.Tensor, Dict[str, Any]]]:
        """
        Forward pass through the LNN.
        
        Args:
            x: Input tensor [batch_size, seq_len, input_size] or [batch_size, input_size]
            hidden_states: Optional list of hidden states for each layer
            return_trajectories: Whether to return state trajectories
            
        Returns:
            Output tensor or (output, info_dict) if return_trajectories=True
        """
        start_time = datetime.now(timezone.utc)
        
        # Handle both sequential and single-step inputs
        if x.dim() == 2:
            x = x.unsqueeze(1)  # Add time dimension
        
        batch_size, seq_len, _ = x.size()
        
        # Initialize hidden states if not provided
        if hidden_states is None:
            hidden_states = [None] * len(self.layers)
        
        # Process through layers
        trajectories = []
        outputs = []
        
        for t in range(seq_len):
            h = x[:, t, :]
            
            for i, layer in enumerate(self.layers):
                h, hidden_states[i] = layer(h, hidden_states[i])
                
                if self.config.save_trajectories:
                    trajectories.append(h.clone())
            
            outputs.append(h)
        
        # Stack outputs
        output = torch.stack(outputs, dim=1)
        
        # Apply temporal attention if sequence
        if seq_len > 1:
            output, _ = self.temporal_attention(
                output.transpose(0, 1),
                output.transpose(0, 1),
                output.transpose(0, 1)
            )
            output = output.transpose(0, 1)
        
        # Squeeze if single step
        if seq_len == 1:
            output = output.squeeze(1)
        
        # Update metrics
        inference_time = (datetime.now(timezone.utc) - start_time).total_seconds() * 1000
        self._update_metrics(inference_time)
        
        if return_trajectories:
            info = {
                'trajectories': trajectories,
                'hidden_states': hidden_states,
                'metrics': self.get_metrics()
            }
            return output, info
        
        return output
    
    def _update_metrics(self, inference_time: float):
        """Update performance metrics."""
        idx = self.inference_count % 100
        self.inference_times[idx] = inference_time
        
        # Estimate memory usage
        total_params = sum(p.numel() for p in self.parameters())
        memory_mb = (total_params * 4) / (1024 * 1024)  # Assuming float32
        self.memory_snapshots[idx] = memory_mb
        
        self.inference_count += 1
        
        # Update metric objects
        self.metrics.inference_time_ms = float(self.inference_times[:self.inference_count].mean())
        self.metrics.memory_usage_mb = float(memory_mb)
        
        # Record to OpenTelemetry
        lnn_inference_time.record(inference_time)
        lnn_memory_usage.set(memory_mb)
    
    def adapt(self, feedback: torch.Tensor):
        """
        Adapt network parameters based on feedback.
        This is the key "liquid" property - adapting without retraining.
        """
        with tracer.start_as_current_span("lnn_adapt"):
            for layer in self.layers:
                if hasattr(layer.cell, 'adapt_parameters'):
                    layer.cell.adapt_parameters(feedback)
            
            self.metrics.adaptation_count += 1
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get current metrics."""
        return {
            'inference_time_ms': self.metrics.inference_time_ms,
            'memory_usage_mb': self.metrics.memory_usage_mb,
            'adaptation_count': self.metrics.adaptation_count,
            'sparsity_ratio': self._calculate_sparsity(),
            'parameter_count': sum(p.numel() for p in self.parameters())
        }
    
    def _calculate_sparsity(self) -> float:
        """Calculate actual sparsity of the network."""
        total_params = 0
        zero_params = 0
        
        for p in self.parameters():
            total_params += p.numel()
            zero_params += (p.abs() < self.config.pruning_threshold).sum().item()
        
        return zero_params / total_params if total_params > 0 else 0.0
    
    def to_edge(self) -> 'EdgeLNN':
        """Convert to edge-optimized version."""
        return EdgeLNN.from_full_model(self)


class EdgeLNN(nn.Module):
    """
    Edge-optimized Liquid Neural Network.
    
    Features:
    - Quantization for reduced memory footprint
    - Pruning for faster inference
    - Optimized ODE solvers for limited compute
    - Power-efficient operations
    """
    
    def __init__(self, config: LNNConfig):
        super().__init__()
        # Force edge-optimized settings
        config.ode_solver = ODESolver.SEMI_IMPLICIT
        config.mixed_precision = False  # Use int8/int16
        config.save_trajectories = False
        config.track_dynamics = False
        
        self.config = config
        self.base_lnn = LiquidNeuralNetwork(config)
        
        # Quantization settings
        self.quantization_scale = 127.0 / 2.0  # int8 range
        self.quantization_zero_point = 0
    
    @classmethod
    def from_full_model(cls, full_model: LiquidNeuralNetwork) -> 'EdgeLNN':
        """Create edge model from full model."""
        config = full_model.config
        config.quantization_bits = 8
        
        edge_model = cls(config)
        
        # Copy and quantize weights
        edge_model._quantize_from_full(full_model)
        
        return edge_model
    
    def _quantize_from_full(self, full_model: LiquidNeuralNetwork):
        """Quantize weights from full precision model."""
        with torch.no_grad():
            for (name, param), (_, full_param) in zip(
                self.named_parameters(),
                full_model.named_parameters()
            ):
                if 'weight' in name or 'W_' in name:
                    # Quantize to int8
                    param.data = self._quantize_tensor(full_param.data)
    
    def _quantize_tensor(self, tensor: torch.Tensor) -> torch.Tensor:
        """Quantize tensor to int8."""
        scale = self.quantization_scale
        zero_point = self.quantization_zero_point
        
        # Quantize
        quantized = torch.round(tensor * scale + zero_point)
        quantized = torch.clamp(quantized, -128, 127)
        
        # Dequantize for computation
        return (quantized - zero_point) / scale
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Optimized forward pass for edge deployment."""
        # Use half precision if available
        if torch.cuda.is_available() and x.is_cuda:
            with torch.cuda.amp.autocast():
                return self.base_lnn(x)
        else:
            # CPU inference with optimizations
            with torch.no_grad():
                return self.base_lnn(x)
    
    def get_edge_metrics(self) -> Dict[str, Any]:
        """Get edge-specific metrics."""
        metrics = self.base_lnn.get_metrics()
        
        # Add edge-specific metrics
        metrics.update({
            'model_size_mb': self._get_model_size(),
            'quantization_bits': self.config.quantization_bits or 32,
            'estimated_power_mw': self._estimate_power_consumption()
        })
        
        return metrics
    
    def _get_model_size(self) -> float:
        """Calculate model size in MB."""
        total_bits = 0
        
        for p in self.parameters():
            bits_per_param = self.config.quantization_bits or 32
            total_bits += p.numel() * bits_per_param
        
        return total_bits / (8 * 1024 * 1024)  # Convert to MB
    
    def _estimate_power_consumption(self) -> float:
        """Estimate power consumption in milliwatts."""
        # Based on research: ~100 microwatts for edge inference
        # Scale by model size and operations
        base_power_uw = 100
        size_factor = self._get_model_size() / 10  # Normalize by 10MB
        
        return base_power_uw * size_factor / 1000  # Convert to mW


class ContinuousTimeRNN(nn.Module):
    """
    A more general continuous-time RNN that can be used as a building block.
    Implements the core CT-RNN equations with various ODE solvers.
    """
    
    def __init__(
        self,
        input_size: int,
        hidden_size: int,
        ode_func: Optional[Callable] = None,
        solver: ODESolver = ODESolver.SEMI_IMPLICIT
    ):
        super().__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.solver = solver
        
        # Default ODE function if not provided
        if ode_func is None:
            self.ode_func = self._default_ode_func
        else:
            self.ode_func = ode_func
        
        # Parameters for default ODE
        self.W_ih = nn.Linear(input_size, hidden_size)
        self.W_hh = nn.Linear(hidden_size, hidden_size)
        self.tau = nn.Parameter(torch.ones(hidden_size))
    
    def _default_ode_func(
        self,
        t: float,
        h: torch.Tensor,
        input: torch.Tensor
    ) -> torch.Tensor:
        """Default ODE: tanh network with time constants."""
        pre_activation = self.W_ih(input) + self.W_hh(h)
        return (-h + torch.tanh(pre_activation)) / self.tau
    
    def forward(
        self,
        input: torch.Tensor,
        hidden: torch.Tensor,
        time_span: Tuple[float, float] = (0.0, 1.0),
        num_steps: int = 10
    ) -> torch.Tensor:
        """
        Solve ODE from t0 to t1.
        """
        t0, t1 = time_span
        dt = (t1 - t0) / num_steps
        
        h = hidden
        for i in range(num_steps):
            t = t0 + i * dt
            
            if self.solver == ODESolver.EULER:
                h = h + dt * self.ode_func(t, h, input)
            elif self.solver == ODESolver.RK4:
                h = self._rk4_step(t, h, input, dt)
            elif self.solver == ODESolver.SEMI_IMPLICIT:
                h = self._semi_implicit_step(t, h, input, dt)
        
        return h
    
    def _rk4_step(
        self,
        t: float,
        h: torch.Tensor,
        input: torch.Tensor,
        dt: float
    ) -> torch.Tensor:
        """Runge-Kutta 4th order step."""
        k1 = self.ode_func(t, h, input)
        k2 = self.ode_func(t + dt/2, h + dt*k1/2, input)
        k3 = self.ode_func(t + dt/2, h + dt*k2/2, input)
        k4 = self.ode_func(t + dt, h + dt*k3, input)
        
        return h + (dt/6) * (k1 + 2*k2 + 2*k3 + k4)
    
    def _semi_implicit_step(
        self,
        t: float,
        h: torch.Tensor,
        input: torch.Tensor,
        dt: float
    ) -> torch.Tensor:
        """Semi-implicit Euler step (more stable)."""
        # For the default ODE, we can solve analytically
        pre_act = self.W_ih(input) + self.W_hh(h)
        target = torch.tanh(pre_act)
        
        # Semi-implicit update
        decay = torch.exp(-dt / self.tau)
        return decay * h + (1 - decay) * target


# Utility functions for LNN deployment
def create_edge_lnn(
    input_size: int,
    hidden_size: int = 128,
    output_size: int = 10,
    num_layers: int = 3
) -> EdgeLNN:
    """Create an edge-optimized LNN with sensible defaults."""
    config = LNNConfig(
        input_size=input_size,
        hidden_size=hidden_size,
        output_size=output_size,
        num_layers=num_layers,
        sparsity=0.9,  # High sparsity for edge
        quantization_bits=8,
        ode_solver=ODESolver.SEMI_IMPLICIT,
        solver_steps=5,  # Fewer steps for speed
        use_cuda=False  # Edge devices typically CPU
    )
    
    return EdgeLNN(config)


def benchmark_lnn(
    model: Union[LiquidNeuralNetwork, EdgeLNN],
    input_shape: Tuple[int, ...],
    num_iterations: int = 100
) -> Dict[str, Any]:
    """Benchmark LNN performance."""
    import time
    
    device = next(model.parameters()).device
    x = torch.randn(*input_shape).to(device)
    
    # Warmup
    for _ in range(10):
        _ = model(x)
    
    # Benchmark
    times = []
    
    for _ in range(num_iterations):
        start = time.perf_counter()
        _ = model(x)
        times.append((time.perf_counter() - start) * 1000)  # ms
    
    return {
        'mean_inference_ms': np.mean(times),
        'std_inference_ms': np.std(times),
        'p50_inference_ms': np.percentile(times, 50),
        'p95_inference_ms': np.percentile(times, 95),
        'p99_inference_ms': np.percentile(times, 99),
        'model_metrics': model.get_metrics() if hasattr(model, 'get_metrics') else {}
    }